---
description: Logging and visualizing experiments with Trackio.
---

# Trackio

The Trackio Experiment Tracker is an [Experiment Tracker](./) flavor provided by the Trackio-ZenML integration. It connects your ZenML pipelines to [Trackio](https://github.com/gradio-app/trackio), a lightweight experiment tracking solution maintained by the Gradio team, so you can visualize and compare the artifacts and metrics generated by your runs.

### When would you want to use it?

Trackio focuses on offering a simple workflow for collecting model metrics and artifacts while staying close to the developer experience that Gradio users are familiar with. You should consider the Trackio Experiment Tracker if:

* you already use Trackio (or plan to) to keep a history of training runs and evaluations and would like to surface the results of your automated ZenML pipelines in the same place
* you prefer a managed experiment tracking option that integrates nicely with the Gradio/Spaces ecosystem without the complexity of heavier experiment tracking suites
* you want to experiment locally with an easy to self-host service before committing to a larger-scale tracking solution

You may want to use one of the other [Experiment Tracker flavors](./#experiment-tracker-flavors) if you rely on advanced governance features (e.g. model registry, lineage dashboards) that are better covered by tools like MLflow, Neptune, or Weights & Biases.

### How do you deploy it?

The Trackio Experiment Tracker flavor is provided through the Trackio ZenML integration. Install the integration to make the component available for registration:

```shell
zenml integration install trackio -y
```

Once installed, you can register the experiment tracker and add it to a stack. The Trackio tracker accepts the following configuration attributes:

* `workspace` (optional): Trackio workspace/organization slug. Leave empty to use the default workspace associated with your API key.
* `project` (optional): Project identifier inside Trackio where new runs should be stored.
* `api_key` (optional): API token used to authenticate against Trackio. When omitted, the library falls back to the environment or CLI authentication.
* `base_url` (optional): Override the default Trackio endpoint, e.g. when talking to a self-hosted Trackio server.

### Authentication methods

You can authenticate with Trackio using the same mechanisms recommended for other experiment trackers. Storing credentials inside a [ZenML Secret](https://docs.zenml.io/how-to/project-setup-and-management/interact-with-secrets) keeps your configuration secure and auditable.

{% tabs %}
{% tab title="ZenML Secret (Recommended)" %}

```shell
zenml secret create trackio_secret --api_key=<TRACKIO_API_KEY>

zenml experiment-tracker register trackio_tracker \
    --flavor=trackio \
    --workspace=<workspace_slug> \
    --project=<project_slug> \
    --api_key={{trackio_secret.api_key}}

zenml stack register trackio_stack -e trackio_tracker ... --set
```

{% endtab %}
{% tab title="Basic authentication" %}

You can also provide the credentials directly on the command line (useful for quick experiments):

```shell
zenml experiment-tracker register trackio_tracker \
    --flavor=trackio \
    --workspace=<workspace_slug> \
    --project=<project_slug> \
    --api_key=<TRACKIO_API_KEY>

zenml stack register trackio_stack -e trackio_tracker ... --set
```

{% hint style="warning" %}
Providing credentials inline is not recommended for production use because they will be stored in plain text in the stack configuration.
{% endhint %}

{% endtab %}
{% endtabs %}

For more information about the configuration parameters supported by the Trackio experiment tracker, refer to the [SDK docs](https://sdkdocs.zenml.io/latest/integration_code_docs/integrations-trackio.html).

### How do you use it?

Once the experiment tracker is part of the active stack, enable it for the steps that should log to Trackio by using the `experiment_tracker` argument of the `@step` decorator. Inside the step you can fetch the Trackio run object and use the regular Trackio API to log metrics, files or metadata:

```python
from zenml import step
from zenml.integrations.trackio.experiment_trackers import get_trackio_run

@step(experiment_tracker="trackio_tracker")
def evaluate_model(accuracy: float, params: dict) -> None:
    run = get_trackio_run()

    # Log high level metrics / metadata using the Trackio client API
    if hasattr(run, "log"):
        run.log({"accuracy": accuracy})
    elif hasattr(run, "log_metrics"):
        run.log_metrics({"accuracy": accuracy})

    if hasattr(run, "log_params"):
        run.log_params(params)
    elif hasattr(run, "__setitem__"):
        run["parameters"] = params
```

Any metadata logged during the step is persisted by Trackio and the resulting dashboard URL is attached to the ZenML run metadata. You can retrieve it programmatically:

```python
from zenml.client import Client

pipeline_run = Client().get_pipeline_run("<PIPELINE_RUN_NAME>")
step = pipeline_run.steps["evaluate_model"]
experiment_tracker_url = step.run_metadata["experiment_tracker_url"].value
```

{% hint style="info" %}
Instead of hardcoding the experiment tracker name, you can obtain it dynamically from the active stack:

```python
from zenml.client import Client

tracker_name = Client().active_stack.experiment_tracker.name

@step(experiment_tracker=tracker_name)
def my_step(...):
    ...
```
{% endhint %}

### Additional settings

The Trackio experiment tracker exposes additional runtime settings that can be provided via the `@step` decorator:

* `run_name`: Override the auto-generated run name that ZenML derives from the pipeline and step names.
* `tags`: Attach custom tags to the Trackio run. ZenML always appends the pipeline name, pipeline run name, and step name to help with filtering.
* `metadata`: Provide a dictionary of values that should be logged immediately after the run is created (e.g. static parameters, environment metadata).

These settings can be declared when defining the step:

```python
from zenml import step
from zenml.integrations.trackio.flavors import TrackioExperimentTrackerSettings

@step(
    experiment_tracker="trackio_tracker",
    settings={
        "experiment_tracker": TrackioExperimentTrackerSettings(
            run_name="nightly-eval",
            tags=["nightly", "evaluation"],
            metadata={"dataset": "imagenet", "split": "validation"},
        )
    },
)
def nightly_evaluation() -> None:
    run = get_trackio_run()
    run.log({"f1": 0.81})
```

As with other experiment trackers, Trackio runs are automatically marked as failed when the corresponding ZenML pipeline step fails.
