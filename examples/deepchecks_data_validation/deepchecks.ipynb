{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/zenml-io/zenml/blob/main/examples/deepchecks_data_validation/deepchecks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO_v5iIaYFi2"
   },
   "source": [
    "# ZenML Data Validation With Deepchecks\n",
    "\n",
    "In data-centric machine learning development, data quality is critical not only\n",
    "to achieve good initial results but also to keep data drift and concept drift\n",
    "at bay as your models are deployed to production and interact with live data.\n",
    "\n",
    "Data validation tools can be employed early on in your machine learning\n",
    "pipelines to generate data quality profiles and to run data validation checks\n",
    "that can be used to continuously validate the data being ingested at various\n",
    "points in the pipeline. For example, data quality reports and checks can be\n",
    "run on the training and validation datasets used during model training, or on\n",
    "the inference data used for batch predictions. This is one good way of detecting\n",
    "training-serving skew.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This example uses [Deepchecks](https://github.com/deepchecks/deepchecks), a\n",
    "feature rich data validation open-source library to painlessly do data validation.\n",
    "Deepchecks can do a variety of data validation tasks, from data integrity checks\n",
    "that work with a single dataset to data+model evaluation to data drift analyses.\n",
    "All this can be done with minimal configuration input from the user, or\n",
    "customized with specialized conditions that the validation checks should perform.\n",
    "\n",
    "At its core, the Deepchecks data validation library takes in a target dataset and\n",
    "an optional model and reference dataset and generates a data validation check\n",
    "result in the form of a `SuiteResult` object that can be analyzed programmatically\n",
    "of visualized in a notebook or in the browser as a HTML webpage.. \n",
    "Datasets come in the form of `pandas` dataframes and models can be anything\n",
    "that implement a `predict` method for regression tasks and also a `predict_proba`\n",
    "method for classification tasks.\n",
    "\n",
    "If you want to run this notebook in an interactive environment, feel free to run\n",
    "it in a [Google Colab](https://colab.research.google.com/github/zenml-io/zenml/blob/main/examples/deepchecks_drift_detection/deepchecks.ipynb)\n",
    "or view it on [GitHub](https://github.com/zenml-io/zenml/tree/main/examples/deepchecks_drift_detection) directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNLEesHEyjkg"
   },
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7l4qDgcI_5F",
    "outputId": "ed764976-0d95-4e5f-e75d-805d2bab804c"
   },
   "outputs": [],
   "source": [
    "# Install the ZenML CLI tool, Deepchecks and scikit-learn\n",
    "\n",
    "!pip install zenml \n",
    "!zenml integration install deepchecks sklearn -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_RCPyaNzPy-"
   },
   "source": [
    "Once the installation is completed, you can go ahead and create a ZenML repository for this project by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lcfE3l2zTU-",
    "outputId": "3d3e70af-c87a-4ac9-917d-b322823431e1"
   },
   "outputs": [],
   "source": [
    "# Initialize a ZenML repository\n",
    "!zenml init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQE8PSXDzL-_"
   },
   "source": [
    "Now, the setup is completed. For the next steps, just make sure that you are executing the code within your ZenML repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to have an Deepchecks Data Validator component to your stack to be able to use Deepchecks data profiling in your ZenML pipelines. Creating such a stack is easily accomplished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!zenml data-validator register deepchecks -f deepchecks\n",
    "!zenml stack register deepchecks_stack -o default -a default -dv deepchecks --set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izjbDO-6yrFM"
   },
   "source": [
    "## Import relevant packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gtj5QKCnSj0"
   },
   "source": [
    "We will use pipelines and steps to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LvFo9epOUE7G",
    "outputId": "42bec4a0-41f9-4560-e9a1-e139f08c4e0a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rich import print\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from zenml.integrations.constants import DEEPCHECKS, SKLEARN\n",
    "from zenml.logger import get_logger\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.steps import Output, step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UwqjAR2yvH_"
   },
   "source": [
    "## Define ZenML Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZI9i2FJ0k3H"
   },
   "source": [
    "The first step is a `data_loader` step that downloads the breast cancer Wisconsin dataset and returns it as a panda DataFrame. We'll use this as the reference dataset for our data drift detection example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1VT_PAW10jbp",
    "outputId": "36ecdd08-3bca-42b4-d84d-be76126840e8"
   },
   "outputs": [],
   "source": [
    "from deepchecks.tabular.datasets.classification import iris\n",
    "\n",
    "LABEL_COL = \"target\"\n",
    "\n",
    "@step\n",
    "def data_loader() -> Output(\n",
    "    reference_dataset=pd.DataFrame, comparison_dataset=pd.DataFrame\n",
    "):\n",
    "    \"\"\"Load the iris dataset.\"\"\"\n",
    "    iris_df = iris.load_data(data_format=\"Dataframe\", as_train_test=False)\n",
    "    df_train, df_test = train_test_split(\n",
    "        iris_df, stratify=iris_df[LABEL_COL], random_state=0\n",
    "    )\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add a model training step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def trainer(df_train: pd.DataFrame) -> ClassifierMixin:\n",
    "    # Train Model\n",
    "    rf_clf = RandomForestClassifier(random_state=0)\n",
    "    rf_clf.fit(df_train.drop(LABEL_COL, axis=1), df_train[LABEL_COL])\n",
    "    return rf_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aU9ygH9s1BgR"
   },
   "source": [
    "Next, we add our Deepchecks validation steps. First, a data integrity check that we'll run against the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37mMICD_URDW",
    "outputId": "873fe64b-1105-4181-8541-c31356069305"
   },
   "outputs": [],
   "source": [
    "from zenml.integrations.deepchecks.steps import (\n",
    "    DeepchecksDataIntegrityCheckStepParameters,\n",
    "    deepchecks_data_integrity_check_step,\n",
    ")\n",
    "\n",
    "data_validator = deepchecks_data_integrity_check_step(\n",
    "    step_name=\"data_validator\",\n",
    "    params=DeepchecksDataIntegrityCheckStepParameters(\n",
    "        dataset_kwargs=dict(label=LABEL_COL, cat_features=[]),\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a Deepchecks data drift check step that we'll use to compare the validation dataset against the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.deepchecks.steps import (\n",
    "    DeepchecksDataDriftCheckStepParameters,\n",
    "    deepchecks_data_drift_check_step,\n",
    ")\n",
    "\n",
    "data_drift_detector = deepchecks_data_drift_check_step(\n",
    "    step_name=\"data_drift_detector\",\n",
    "    params=DeepchecksDataDriftCheckStepParameters(\n",
    "        dataset_kwargs=dict(label=LABEL_COL, cat_features=[]),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a Deepchecks model evaluation check step to run it against our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.deepchecks.steps import (\n",
    "    DeepchecksModelValidationCheckStepParameters,\n",
    "    deepchecks_model_validation_check_step,\n",
    ")\n",
    "\n",
    "model_validator = deepchecks_model_validation_check_step(\n",
    "    step_name=\"model_validator\",\n",
    "    params=DeepchecksModelValidationCheckStepParameters(\n",
    "        dataset_kwargs=dict(label=LABEL_COL, cat_features=[]),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, add a Deepchecks model drift check step to compare the performance of the model against two datasets: our original training dataset and the data validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.deepchecks.steps import (\n",
    "    DeepchecksModelDriftCheckStepParameters,\n",
    "    deepchecks_model_drift_check_step,\n",
    ")\n",
    "\n",
    "model_drift_detector = deepchecks_model_drift_check_step(\n",
    "    step_name=\"model_drift_detector\",\n",
    "    params=DeepchecksModelDriftCheckStepParameters(\n",
    "        dataset_kwargs=dict(label=LABEL_COL, cat_features=[]),\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_iZTIz8y7Cp"
   },
   "source": [
    "## Define ZenML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKbU3WlbnoiA"
   },
   "source": [
    "A pipeline is defined with the `@pipeline` decorator. This defines the various steps of the pipeline and specifies the dependencies between the steps, thereby determining the order in which they will be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rm8SIrLFWenn"
   },
   "outputs": [],
   "source": [
    "from zenml.config import DockerSettings\n",
    "docker_settings = DockerSettings(required_integrations=[DEEPCHECKS, SKLEARN])\n",
    "\n",
    "@pipeline(enable_cache=False, settings={\"docker\": docker_settings})\n",
    "def data_validation_pipeline(\n",
    "    data_loader,\n",
    "    trainer,\n",
    "    data_validator,\n",
    "    model_validator,\n",
    "    data_drift_detector,\n",
    "    model_drift_detector,\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    df_train, df_test = data_loader()\n",
    "    data_validator(dataset=df_train)\n",
    "    data_drift_detector(\n",
    "        reference_dataset=df_train,\n",
    "        target_dataset=df_test,\n",
    "    )\n",
    "    model = trainer(df_train)\n",
    "    model_validator(dataset=df_train, model=model)\n",
    "    model_drift_detector(\n",
    "        reference_dataset=df_train, target_dataset=df_test, model=model\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-JtDHu_z1IX"
   },
   "source": [
    "## Run the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrJA5OSgnydC"
   },
   "source": [
    "Running the pipeline is as simple as calling the `run()` method on an instance of the defined pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRzZA406UVVz",
    "outputId": "2d5e9967-87b7-4553-a104-b1b6602e10a6"
   },
   "outputs": [],
   "source": [
    "pipeline_instance = data_validation_pipeline(\n",
    "    data_loader=data_loader(),\n",
    "    trainer=trainer(),\n",
    "    data_validator=data_validator,\n",
    "    model_validator=model_validator,\n",
    "    data_drift_detector=data_drift_detector,\n",
    "    model_drift_detector=model_drift_detector,\n",
    ")\n",
    "pipeline_instance.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-execution workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize all the validation check results from the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_instance.run()\n",
    "\n",
    "last_run = pipeline_instance.get_runs()[0]\n",
    "data_val_step = last_run.get_step(step=data_validator)\n",
    "model_val_step = last_run.get_step(step=model_validator)\n",
    "data_drift_step = last_run.get_step(step=data_drift_detector)\n",
    "model_drift_step = last_run.get_step(step=model_drift_detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val_step.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_val_step.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drift_step.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_drift_step.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOJtVVaFzlUO"
   },
   "source": [
    "You have successfully used ZenML and Deepchecks to validate data and generate a validation report.\n",
    "\n",
    "For more ZenML features and use-cases, you should check out some of the other ZenML examples. You should also take a look at our [docs](https://docs.zenml.io/) or our [Github](https://github.com/zenml-io/zenml) repo, or even better, join us on our [Slack channel](https://zenml.io/slack-invite).\n",
    "\n",
    "Cheers!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ZenML Quickstart.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "92bd632b13ad08a98e6c591fb282887679d737095c495564873743f0fe7001fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
