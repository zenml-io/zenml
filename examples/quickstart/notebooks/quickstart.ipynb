{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "RO_v5iIaYFi2"
   },
   "source": [
    "# ZenML Quickstart Guide\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/zenml-io/zenml/blob/main/examples/quickstart/notebooks/quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "This quickstart helps you get your first practical experience with ZenML and gives you a brief overview of various MLOps terms. \n",
    "\n",
    "Throughout this quickstart, we will:\n",
    "- Train a model, evaluate it, register the model version, deploy it, and embed it in an inference pipeline,\n",
    "- Automatically version, track, and cache data, models, and other artifacts,\n",
    "- Track model hyperparameters and metrics in an experiment tracking tool,\n",
    "- Measure and visualize train-test skew, training-serving skew, and data drift."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we dive into the code, let us briefly introduce you to some of the \n",
    "fundamental concepts of ZenML that we will use in this quickstart. If you are \n",
    "already familiar with these concepts, feel free to skip to the next section.\n",
    "\n",
    "#### Steps\n",
    "\n",
    "The first concept that we will cover is the ZenML **Step**. In \n",
    "ZenML, a step provides a simple python interface to our users to design a \n",
    "stand-alone process in an ML workflow. They consume input artifacts \n",
    "and generate output artifacts. As an example, we can take a closer look at a \n",
    "simple step example:\n",
    "\n",
    "```python\n",
    "from zenml import step\n",
    "\n",
    "@step\n",
    "def my_dataset_loader() -> pd.DataFrame:\n",
    "    \"\"\"My dataset loader step.\"\"\"\n",
    "    # Implement logic here and return the dataset...\n",
    "    return ...\n",
    "```\n",
    "\n",
    "#### Pipelines\n",
    "\n",
    "Following the steps, you will go over the concepts of **Pipelines**. These \n",
    "pipelines provide our users a simple python interface to design their ML \n",
    "workflows by linking different steps together. For instance, a very \n",
    "simple pipeline might look like this:\n",
    "\n",
    "```python\n",
    "from zenml import pipeline\n",
    "\n",
    "@pipeline\n",
    "def my_pipeline(\n",
    "    my_data_loader,\n",
    "    my_model_trainer,\n",
    "):\n",
    "    \"\"\"Load the dataset and train a model.\"\"\"\n",
    "    dataset = my_data_loader()\n",
    "    model = my_model_trainer(dataset=dataset)\n",
    "```\n",
    "\n",
    "#### Stacks & Stack Components\n",
    "\n",
    "As for the execution of these pipelines, you need a **stack**. In ZenML, \n",
    "a stack stands for a set of configurations of your MLOps tools and \n",
    "infrastructure. Each stack consists of multiple **stack components** and\n",
    "depending on their type, these components serve different purposes.\n",
    "\n",
    "If you look at some examples of different flavors of stack components, you \n",
    "will see examples such as:\n",
    "\n",
    "- [Airflow**Orchestrator**](https://docs.zenml.io/component-gallery/orchestrators/airflow) which orchestrates your ML workflows on Airflow \n",
    "- [MLflow**ExperimentTracker**](https://docs.zenml.io/component-gallery/experiment-trackers/mlflow) which can track your experiments with MLFlow\n",
    "- [Evidently**DataValidator**](https://docs.zenml.io/component-gallery/data-validators/evidently) which can help you validate your data\n",
    "\n",
    "Any such combination of tools and infrastructure can be registered as a \n",
    "separate stack in ZenML. Since ZenML code is tooling-independent, you can \n",
    "switch between stacks with a single command and then automatically execute your\n",
    "ML workflows on the desired stack without having to modify your code.\n",
    "\n",
    "#### Integrations\n",
    "\n",
    "Finally, ZenML comes equipped with a wide variety of stack components flavors. \n",
    "While some of these flavors come built-in with the ZenML package, the others \n",
    "are implemented as a part of one of our integrations. Since our quickstart \n",
    "features some of these integrations, you will see a practical example on how \n",
    "to use these integrations in the upcoming sections."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "VNLEesHEyjkg"
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for the quickstart, we need to install some dependencies. Once you have ZenML installed, you can use our CLI to install the required integrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"zenml[server]\"  # install ZenML\n",
    "!zenml integration install sklearn mlflow evidently -y  # install ZenML integrations\n",
    "!zenml init  # Initialize a ZenML repository\n",
    "%pip install pyparsing==2.4.2  # required for Colab\n",
    "\n",
    "import IPython\n",
    "\n",
    "# automatically restart kernel\n",
    "IPython.Application.instance().kernel.do_shutdown(restart=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please wait for the installation to complete before running subsequent cells. At the end of the installation, the notebook kernel will automatically restart."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Google Colab\n",
    "\n",
    "If you follow this quickstart in Google's Colab, you will need an [ngrok account](https://dashboard.ngrok.com/signup) to view some of the visualizations later. Please set up an account, then set your user token below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGROK_TOKEN = \"\"  # TODO: set your ngrok token if you are working on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.environment import Environment\n",
    "\n",
    "if Environment.in_google_colab():  # Colab only setup\n",
    "    # install ngrok and set auth token\n",
    "    !pip install pyngrok\n",
    "    !ngrok authtoken {NGROK_TOKEN}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an MLOps Stack\n",
    "\n",
    "ZenML decouples your code from the infrastructure and tooling you use.\n",
    "This enables you to quickly take your code from experimentation to production.\n",
    "Furthermore, using ZenML prevents vendor lock-in by allowing you to switch out any part of your MLOps stack easily.\n",
    "See the [ZenML Integrations](https://zenml.io/integrations) page for a list of all tools we currently support.\n",
    "\n",
    "Throughout this quickstart, we will use the following MLOps stack: A local orchestrator, a local artifact store, [MLFlow](https://mlflow.org/) experiment tracker and model deployer, and an [Evidently](https://evidentlyai.com/) data validator.\n",
    "\n",
    "![Quickstart MLOps Stack Overview](_assets/stack_overview_2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, we need to register all stack components that require configuration into our ZenML MLOps stack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the MLflow experiment tracker\n",
    "!zenml experiment-tracker register mlflow_tracker --flavor=mlflow\n",
    "\n",
    "# Register the MLflow model registry\n",
    "!zenml model-registry register mlflow_registry --flavor=mlflow\n",
    "\n",
    "# Register the MLflow model deployer\n",
    "!zenml model-deployer register mlflow_deployer --flavor=mlflow\n",
    "\n",
    "# Register the Evidently data validator\n",
    "!zenml data-validator register evidently_validator --flavor=evidently\n",
    "\n",
    "# Register a new stack with the new stack components\n",
    "!zenml stack register quickstart_stack -a default\\\n",
    "                                       -o default\\\n",
    "                                       -d mlflow_deployer\\\n",
    "                                       -e mlflow_tracker\\\n",
    "                                       -r mlflow_registry\\\n",
    "                                       -dv evidently_validator\\\n",
    "\n",
    "!zenml stack set quickstart_stack\n",
    "\n",
    "# Visualize the current ZenML stack\n",
    "!zenml stack describe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ML Pipelines\n",
    "Let us now use ZenML to write two ML pipelines for continuous training and serving.\n",
    "\n",
    "The training pipeline will:\n",
    "- Load the [iris flower classification dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html),\n",
    "- Train a model on the training data (and track hyperparameters using [MLFlow](https://mlflow.org/)),\n",
    "- Test the model on the test data,\n",
    "- Register the model (with [MLFlow](https://mlflow.org/))\n",
    "\n",
    "The inference pipeline will:\n",
    "- Load inference data,\n",
    "- Deploy a chosen version of registered model,\n",
    "- Run model inference on the inference data,\n",
    "- Check for data drift (with [Evidently](https://evidentlyai.com/)).\n",
    "\n",
    "You can see a visualization of the two pipelines below:\n",
    "\n",
    "![Overview of Quickstart Pipelines](_assets/quickstart_pipelines.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Pipeline Steps\n",
    "\n",
    "Let's now implement the steps that make up these pipelines. We can do this by \n",
    "writing simple Python functions and decorating them with ZenML's `@step` decorator.\n",
    "\n",
    "In total, we will need ten steps:\n",
    "- Training data loader\n",
    "- Inference data loader\n",
    "- Model trainer\n",
    "- Model evaluator\n",
    "- Model registerer\n",
    "- Inference data loader\n",
    "- Registered model deployer\n",
    "- Predictor\n",
    "- Skew comparison\n",
    "- Drift detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders\n",
    "Let's start with data loading. We load the iris dataset for training and, for simplicity, use some random samples for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from zenml import step\n",
    "from zenml.steps import Output\n",
    "\n",
    "\n",
    "@step\n",
    "def training_data_loader() -> Output(\n",
    "    X_train=pd.DataFrame,\n",
    "    X_test=pd.DataFrame,\n",
    "    y_train=pd.Series,\n",
    "    y_test=pd.Series,\n",
    "):\n",
    "    \"\"\"Load the iris dataset as tuple of Pandas DataFrame / Series.\"\"\"\n",
    "    iris = load_iris(as_frame=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        iris.data, iris.target, test_size=0.2, shuffle=True, random_state=42\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def inference_data_loader() -> pd.DataFrame:\n",
    "    \"\"\"Load some (random) inference data.\"\"\"\n",
    "    return pd.DataFrame(\n",
    "        data=np.random.rand(10, 4) * 10,  # assume range [0, 10]\n",
    "        columns=load_iris(as_frame=True).data.columns,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Trainer\n",
    "To train our model, we define two steps that use the [sklearn SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) model and [Decision Tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) classifier and fit them on the given training data. Additionally, we log all model hyperparameters and metrics to [MLFlow](https://mlflow.org/).\n",
    "\n",
    "Note that we do not need to save the model within the step explicitly; ZenML is automatically taking care of this for us. Under the hood, ZenML persists all step inputs and outputs in an [Artifact Store](https://docs.zenml.io/component-gallery/artifact-stores). This also means that all of our data and models are automatically versioned and tracked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from zenml.client import Client\n",
    "\n",
    "experiment_tracker = Client().active_stack.experiment_tracker\n",
    "\n",
    "@step(enable_cache=False, experiment_tracker=experiment_tracker.name)\n",
    "def svc_trainer_mlflow(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    ") -> ClassifierMixin:\n",
    "    \"\"\"Train a sklearn SVC classifier and log to MLflow.\"\"\"\n",
    "    mlflow.sklearn.autolog()  # log all model hparams and metrics to MLflow\n",
    "    model = SVC(gamma=0.01)\n",
    "    model.fit(X_train.to_numpy(), y_train.to_numpy())\n",
    "    train_acc = model.score(X_train.to_numpy(), y_train.to_numpy())\n",
    "    print(f\"Train accuracy: {train_acc}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from zenml.client import Client\n",
    "\n",
    "experiment_tracker = Client().active_stack.experiment_tracker\n",
    "\n",
    "@step(enable_cache=False, experiment_tracker=experiment_tracker.name)\n",
    "def tree_trainer_mlflow(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    ") -> ClassifierMixin:\n",
    "    \"\"\"Train a decision tree classifier and log to MLflow.\"\"\"\n",
    "    mlflow.sklearn.autolog()  # log all model hparams and metrics to MLflow\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train.to_numpy(), y_train.to_numpy())\n",
    "    train_acc = model.score(X_train.to_numpy(), y_train.to_numpy())\n",
    "    print(f\"Train accuracy: {train_acc}\")\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluator and Deployment Trigger\n",
    "\n",
    "Since our model is a [sklearn Model](https://scikit-learn.org/stable/developers/develop.html), we can simply call `model.score` to compute its test accuracy.\n",
    "\n",
    "We then use the output of this step to only trigger deployment for models that achieved >90% test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def evaluator(\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    "    model: ClassifierMixin,\n",
    ") -> float:\n",
    "    \"\"\"Calculate the accuracy on the test set\"\"\"\n",
    "    test_acc = model.score(X_test.to_numpy(), y_test.to_numpy())\n",
    "    print(f\"Test accuracy: {test_acc}\")\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def deployment_trigger(test_acc: float) -> bool:\n",
    "    \"\"\"Only deploy if the test accuracy > 90%.\"\"\"\n",
    "    return test_acc > 0.9"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Registry, Deployer and Drift Detection\n",
    "\n",
    "ZenML provides default steps for MLflow model registry, deployment and Evidently drift detection, which we can simply import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.mlflow.steps.mlflow_deployer import mlflow_model_registry_deployer_step\n",
    "from zenml.integrations.mlflow.steps.mlflow_registry import mlflow_register_model_step\n",
    "from zenml.model_registries.base_model_registry import ModelRegistryModelMetadata\n",
    "\n",
    "model_deployer = mlflow_model_registry_deployer_step.with_options(\n",
    "    parameters=dict(\n",
    "        registry_model_name=\"zenml-quickstart-model\",\n",
    "        registry_model_version=\"1\",\n",
    "        # or you can use the model stage if you have set it in the MLflow registry\n",
    "        # registered_model_stage=\"None\" # \"Staging\", \"Production\", \"Archived\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.evidently.steps import (\n",
    "    evidently_profile_step,\n",
    ")\n",
    "\n",
    "drift_detector = evidently_profile_step.with_options(\n",
    "    parameters=dict(profile_sections=[\"datadrift\"])\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Service Loader and Predictor\n",
    "\n",
    "Lastly, we need to write the inference pipeline steps for loading a deployed model and computing its prediction on the test data.\n",
    "\n",
    "To load the deployed model, we query ZenML's artifact store to find a model deployed with our current MLOps stack and the given training pipeline and deployment step names (more on this later):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.services import BaseService\n",
    "from zenml.client import Client\n",
    "\n",
    "\n",
    "@step(enable_cache=False)\n",
    "def prediction_service_loader() -> BaseService:\n",
    "    \"\"\"Load the model service of our train_evaluate_deploy_pipeline.\"\"\"\n",
    "    client = Client()\n",
    "    model_deployer = client.active_stack.model_deployer\n",
    "    services = model_deployer.find_model_server(\n",
    "        pipeline_name=\"training_pipeline\",\n",
    "        pipeline_step_name=\"model_deployer\",\n",
    "        running=True,\n",
    "    )\n",
    "    service = services[0]\n",
    "    return service"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inference the deployed model, we simply call its `predict()` method to get logits and compute the `argmax` to obtain the final prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def predictor(\n",
    "    service: BaseService,\n",
    "    data: pd.DataFrame,\n",
    ") -> Output(predictions=list):\n",
    "    \"\"\"Run a inference request against a prediction service\"\"\"\n",
    "    service.start(timeout=10)  # should be a NOP if already started\n",
    "    prediction = service.predict(data.to_numpy())\n",
    "    prediction = prediction.argmax(axis=-1)\n",
    "    print(f\"Prediction is: {[prediction.tolist()]}\")\n",
    "    return [prediction.tolist()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Run Pipelines\n",
    "\n",
    "Let's now define the pipelines with ZenML. To do so, we simply write a Python function that defines how the data will move through the different steps and decorate it with ZenML's `@pipeline` decorator. Under the hood, ZenML will build a [DAG](https://en.wikipedia.org/wiki/Directed_acyclic_graph) that determines the order in which the steps need to be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from zenml import pipeline\n",
    "\n",
    "@pipeline(enable_cache=False)\n",
    "def training_pipeline():\n",
    "    \"\"\"Train, evaluate, and deploy a model.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = training_data_loader()\n",
    "    model = svc_trainer_mlflow(X_train=X_train, y_train=y_train)\n",
    "    evaluator(X_test=X_test, y_test=y_test, model=model)\n",
    "    mlflow_register_model_step(\n",
    "        model,\n",
    "        name=\"zenml-quickstart-model\",\n",
    "        metadata=ModelRegistryModelMetadata(gamma=0.01, arch=\"svc\"),\n",
    "        description=\"The first run of the Quickstart pipeline.\",\n",
    "    )(model)\n",
    "\n",
    "training_pipeline()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's replace the SVC trainer with the Tree trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@pipeline(enable_cache=False)\n",
    "def training_pipeline():\n",
    "    \"\"\"Train, evaluate, and deploy a model.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = training_data_loader()\n",
    "    model = tree_trainer_mlflow(X_train=X_train, y_train=y_train)\n",
    "    evaluator(X_test=X_test, y_test=y_test, model=model)\n",
    "    mlflow_register_model_step(\n",
    "        model,\n",
    "        name=\"zenml-quickstart-model\",\n",
    "        metadata=ModelRegistryModelMetadata(arch=\"decision_tree\"),\n",
    "        description=\"The second run of the Quickstart pipeline.\",\n",
    "    )\n",
    "\n",
    "training_pipeline()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the second pipeline ran slightly faster than the first? That's because ZenML understands that the `data_loader` step of your pipeline is unchanged, so it just reloads the output from your previous run and goes straight to the trainer part. This saves valuable time as you iterate on your pipeline."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference pipeline to deploy and inference on the registered model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training pipeline runs have finished, the trained model will have been registered using MLflow Model registry. We can use `zenml model-registry models list` to get an overview of all currently registered models and `zenml model-registry models list-versions` to get an overview of all versions of a specific model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml model-registry models list\n",
    "\n",
    "!zenml model-registry models list-versions zenml-quickstart-model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run the inference pipeline, the `mlflow_model_registry_deployer_step` will load the given model version and deploy it locally. After that, the `predictor` step will use the deployed model service to make predictions on the inference data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline()\n",
    "def inference_pipeline():\n",
    "    \"\"\"Inference pipeline with skew and drift detection.\"\"\"\n",
    "    inference_data = inference_data_loader()\n",
    "    model_deployment_service = model_deployer()\n",
    "    predictor(service=model_deployment_service, data=inference_data)\n",
    "    training_data, _, _, _ = training_data_loader()\n",
    "    drift_detector(training_data, inference_data)\n",
    "\n",
    "inference_pipeline()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run `zenml model-deployer models list` to get an overview of all currently deployed models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml model-deployer models list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting the outcomes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZenML dashboard\n",
    "\n",
    "Once the pipeline runs have completed, we can visualize all of our ZenML \n",
    "resources in the ZenML dashboard. \n",
    "In order to spin up the dashboard, please execute the following code cell.\n",
    "\n",
    "**Colab Note:** On Colab, you can access the ZenML dashboard via the \n",
    "`...ngrok.io` URL that will be shown in the first line of the output of the \n",
    "following code cell.\n",
    "Please wait for the server to fully start up before accessing the dashboard URL, \n",
    "otherwise some resources might not have been fully loaded yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.environment import Environment\n",
    "\n",
    "\n",
    "def start_zenml_dashboard(port=8237):\n",
    "    if Environment.in_google_colab():\n",
    "        from pyngrok import ngrok\n",
    "\n",
    "        public_url = ngrok.connect(port)\n",
    "        print(f\"\\x1b[31mIn Colab, use this URL instead: {public_url}!\\x1b[0m\")\n",
    "        !zenml up --blocking --port {port}\n",
    "\n",
    "    else:\n",
    "        !zenml up --port {port}\n",
    "\n",
    "start_zenml_dashboard()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a local ZenML server and connect you to it. Once connected, \n",
    "the dashboard will be available for you at the URL displayed in the command\n",
    "output above. You can login with username `default` and an empty password.\n",
    "\n",
    "![ZenML Server Up](_assets/zenml-up.gif)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this dashboard, you will be able to manage your pipelines and the corresponding pipeline runs, your stacks and stack components and your personal settings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data Skew and Data Drift\n",
    "\n",
    "ZenML automatically saves visualizations for many common data types. You can\n",
    "either view these visualizations in the dashboard by clicking on the respective \n",
    "artifact in the pipeline run DAG, or you can view them in Jupyter notebooks\n",
    "using the `visualize()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_run = inference_pipeline.get_runs()[0]\n",
    "drift_detection_step = inference_run.get_step(step=\"evidently_profile_step\")\n",
    "drift_detection_step.visualize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accordingly, Evidently will also detect data drift for all four features:\n",
    "\n",
    "<img src=\"_assets/data_drift.png\" alt=\"Evidently Data Drift Visualization\" width=\"50%\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Experiment Tracking\n",
    "\n",
    "Lastly, remember how we added MLflow experiment tracking to our `svc_trainer_mlflow` step before?\n",
    "Those two simple lines of code automatically configured and initialized MLflow and logged all hyperparameters and metrics there.\n",
    "\n",
    "Let's start up the MLflow UI and check it out!\n",
    "\n",
    "**Colab Note:** On Colab, you can access the MLflow UI via the `...ngrok.io` URL\n",
    "that will be shown in the first line of the output of the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.constants import METADATA_EXPERIMENT_TRACKER_URL\n",
    "\n",
    "trainer_step = training_pipeline.get_runs()[0].get_step(\"svc_trainer_mlflow\")\n",
    "tracking_uri = trainer_step.metadata[METADATA_EXPERIMENT_TRACKER_URL].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.environment import Environment\n",
    "\n",
    "\n",
    "def open_mlflow_ui(port=4997):\n",
    "    if Environment.in_google_colab():\n",
    "        from pyngrok import ngrok\n",
    "\n",
    "        public_url = ngrok.connect(port)\n",
    "        print(f\"\\x1b[31mIn Colab, use this URL instead: {public_url}!\\x1b[0m\")\n",
    "\n",
    "    !mlflow ui --backend-store-uri=\"{tracking_uri}\" --port={port}\n",
    "\n",
    "\n",
    "open_mlflow_ui()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLflow UI](_assets/mlflow_ui.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You just built your first ML Pipeline! You not only trained a model, you also deployed it, served it, and learned how to monitor and visualize everything that's going on. Did you notice how easy it was to bring all of the different components together using ZenML's abstractions? And that is just the tip of the iceberg of what ZenML can do; check out the [**Integrations**](https://zenml.io/integrations) page for a list of all the cool MLOps tools that ZenML supports!\n",
    "\n",
    "To improve upon the ML workflows we built in this quickstart, you could, for instance:\n",
    "- [Deploy ZenML on the Cloud]() to collaborate with your teammates,\n",
    "- Experiment with more sophisticated models, such as [XGBoost](https://zenml.io/integrations/xgboost),\n",
    "- Set up automated [Slack alerts](https://zenml.io/integrations/zen-ml-slack-integration) to get notified when data drift happens,\n",
    "- Run the pipelines on scalable, distributed stacks like [Kubeflow](https://zenml.io/integrations/kubeflow)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to go next\n",
    "\n",
    "* If you have questions or feedback... \n",
    "  * Join our [**Slack Community**](https://zenml.io/slack-invite) and become part of the ZenML family!\n",
    "* If this quickstart was a bit too quick for you... \n",
    "  * Check out [**ZenBytes**](https://github.com/zenml-io/zenbytes), our lesson series on practical MLOps, where we cover each MLOps concept in much more detail.\n",
    "* If you want to learn more about using or extending ZenML...\n",
    "  * Check out our [**Docs**](https://docs.zenml.io/) or read through our code on [**Github**](https://github.com/zenml-io/zenml).\n",
    "* If you want to quickly learn how to use a specific tool with ZenML...\n",
    "  * Check out our collection of [**Examples**](https://github.com/zenml-io/zenml/tree/doc/hamza-misc-updates/examples).\n",
    "* If you want to see some advanced ZenML use cases... \n",
    "  * Check out [**ZenML Projects**](https://github.com/zenml-io/zenml-projects), our collection of production-grade ML use-cases."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ZenML Quickstart.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6d2a2855dd99d151bf9fdc91431d39c1e05805b2488b8cd3e8da8d54747db678"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
