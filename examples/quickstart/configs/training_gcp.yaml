# Environment configuration
settings:
  resources:
    memory: 64GB
  docker:
    parent_image: "zenmldocker/zenml-public-pipelines:quickstart-0.65.0-py3.11-gcp"
    skip_build: True
# Uncomment the following two lines to specify the accelerator for your vertex orchestrator
#  orchestrator.vertex:
#    node_selector_constraint: ["cloud.google.com/gke-accelerator", "NVIDIA_TESLA_P4"]

# Model Control Plane configuration
model:
  name: YeOldeEnglishTranslator
  description: Model to translate from old to modern english
  tags: ["quickstart", "llm", "t5"]

# Configure the pipeline
parameters:
  # model_type: "t5-small"  # Choose between t5-small and t5-large
  num_train_epochs: 2
  per_device_train_batch_size: 16
  gradient_accumulation_steps: 4
  dataloader_num_workers: 0

# Per step configuration
steps:
  split_dataset:
    parameters:
      subset_size: 0.5  # only use 50% of all available data
      train_size: 0.7
      test_size: 0.1
      eval_size: 0.2
      random_state: 42
  load_data:
    parameters:
      data_url: 'https://storage.googleapis.com/zenml-public-bucket/quickstart-files/translations.txt'
