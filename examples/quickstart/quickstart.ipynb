{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/zenml-io/zenml/blob/main/examples/quickstart/quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO_v5iIaYFi2"
   },
   "source": [
    "# ZenML Quickstart Guide\n",
    "\n",
    "Our goal here is to help you to get the first practical experience with our tool and give you a brief overview on some basic functionalities of ZenML. We'll create a training pipeline for the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset and then later the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset developed by Zalando.\n",
    "\n",
    "If you want to run this notebook in an interactive environment, feel free to run it in a [Google Colab](https://colab.research.google.com/github/zenml-io/zenml/blob/main/examples/quickstart/quickstart.ipynb) or view it on [GitHub](https://github.com/zenml-io/zenml/tree/main/examples/quickstart) directly.\n",
    "\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This quickstart guide is designed to provide a practical introduction to some of the main concepts and paradigms used by the ZenML framework. If you want more detail, our [full documentation](https://docs.zenml.io/) provides more on the concepts and how to implement them.\n",
    "\n",
    "## Using Google Colab\n",
    "\n",
    "You will want to use a GPU for this example. If you are following this quickstart in Google's Colab, follow these steps:\n",
    "\n",
    "- Before running anything, you need to tell Colab that you want to use a GPU. You can do this by clicking on the ‘Runtime’ tab and selecting ‘Change runtime type’. A pop-up window will open up with a drop-down menu.\n",
    "- Select ‘GPU’ from the menu and click ‘Save’.\n",
    "- It may ask if you want to restart the runtime. If so, go ahead and do that.\n",
    "\n",
    "<!-- The code for the MNIST training borrows heavily from [this](https://www.tensorflow.org/datasets/keras_example) -->\n",
    "\n",
    "## Relation to quickstart.py\n",
    "This notebook is a variant of [quickstart.py](https://github.com/zenml-io/zenml/blob/main/examples/quickstart/quickstart.py) which is shown off in the [ZenML Docs](https://docs.zenml.io). The core difference being it adds a modular aspect of the importer step and shows how to fetch pipelines, runs, and artifacts in the post-execution workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNLEesHEyjkg"
   },
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7l4qDgcI_5F",
    "outputId": "ed764976-0d95-4e5f-e75d-805d2bab804c"
   },
   "outputs": [],
   "source": [
    "# Install the ZenML CLI tool and Tensorflow\n",
    "!pip install zenml \n",
    "!zenml integration install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_RCPyaNzPy-"
   },
   "source": [
    "Once the installation is completed, you can go ahead and create your first ZenML repository for your project. As ZenML repositories are built on top of Git repositories, you can create yours in a desired empty directory through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lcfE3l2zTU-",
    "outputId": "3d3e70af-c87a-4ac9-917d-b322823431e1"
   },
   "outputs": [],
   "source": [
    "# Initialize a ZenML repository\n",
    "!zenml init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQE8PSXDzL-_"
   },
   "source": [
    "Now, the setup is completed. For the next steps, just make sure that you are executing the code within your ZenML repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izjbDO-6yrFM"
   },
   "source": [
    "## Import relevant packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gtj5QKCnSj0"
   },
   "source": [
    "We will use pipelines and steps to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LvFo9epOUE7G",
    "outputId": "42bec4a0-41f9-4560-e9a1-e139f08c4e0a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import ClassifierMixin\n",
    "\n",
    "from zenml.integrations.sklearn.helpers.digits import (\n",
    "    get_digits,\n",
    ")\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.steps import Output, step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UwqjAR2yvH_"
   },
   "source": [
    "## Define ZenML Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wHcI2FinX2O"
   },
   "source": [
    "In the code that follows, you can see that we are defining the various steps of our pipeline. Each step is decorated with `@step`, the main abstraction that is currently available for creating pipeline steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZI9i2FJ0k3H"
   },
   "source": [
    "The first step is an `import` step that downloads the MNIST dataset and returns four numpy arrays as its output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1VT_PAW10jbp",
    "outputId": "36ecdd08-3bca-42b4-d84d-be76126840e8"
   },
   "outputs": [],
   "source": [
    "@step\n",
    "def importer() -> Output(\n",
    "    X_train=np.ndarray, X_test=np.ndarray, y_train=np.ndarray, y_test=np.ndarray\n",
    "):\n",
    "    \"\"\"Loads the digits array as normal numpy arrays.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = get_digits()\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ma53mucU0yF3"
   },
   "source": [
    "We then add a `Trainer` step, that takes the imported data and trains a sklearn classifier on the data. Note that the model is not explicitly saved within the step. Under the hood ZenML uses Materializers to automatically persist the Artifacts that result from each step into the Artifact Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZEw7Cbqx0wXj",
    "outputId": "0603fa51-eb20-4c22-d499-9e7f1f3a972b"
   },
   "outputs": [],
   "source": [
    "@step\n",
    "def decision_tree_trainer(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    ") -> ClassifierMixin:\n",
    "    \"\"\"Train another simple sklearn classifier for the digits dataset.\"\"\"\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aU9ygH9s1BgR"
   },
   "source": [
    "Finally, we add an `Evaluator` step that takes as input the test set and the trained model and evaluates some final metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37mMICD_URDW",
    "outputId": "873fe64b-1105-4181-8541-c31356069305"
   },
   "outputs": [],
   "source": [
    "@step\n",
    "def evaluator(\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    model: ClassifierMixin,\n",
    ") -> float:\n",
    "    \"\"\"Calculate the accuracy on the test set\"\"\"\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "    print(f\"Test accuracy: {test_acc}\")\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_iZTIz8y7Cp"
   },
   "source": [
    "## Define ZenML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKbU3WlbnoiA"
   },
   "source": [
    "A pipeline is defined with the `@pipeline` decorator. This defines the various steps of the pipeline and specifies the dependencies between the steps, thereby determining the order in which they will be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rm8SIrLFWenn"
   },
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def mnist_pipeline(\n",
    "    importer,\n",
    "    trainer,\n",
    "    evaluator,\n",
    "):\n",
    "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
    "    X_train, X_test, y_train, y_test = importer()\n",
    "    model = trainer(X_train=X_train, y_train=y_train)\n",
    "    evaluator(X_test=X_test, y_test=y_test, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-JtDHu_z1IX"
   },
   "source": [
    "## Run the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrJA5OSgnydC"
   },
   "source": [
    "Running the pipeline is as simple as calling the `run()` method on an instance of the defined pipeline. Here we explicitly name our pipeline run to make it easier to access later on. Be aware that you can only run the pipeline once with this name. To rerun, rename the the run, or remove the run name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRzZA406UVVz",
    "outputId": "2d5e9967-87b7-4553-a104-b1b6602e10a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mCreating run for pipeline: `\u001b[0m\u001b[33;21mmnist_pipeline`\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mCache enabled for pipeline `\u001b[0m\u001b[33;21mmnist_pipeline`\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing stack `\u001b[0m\u001b[33;21mlocal_stack`\u001b[1;35m to run pipeline `\u001b[0m\u001b[33;21mmnist_pipeline`\u001b[1;35m...\u001b[0m\n",
      "\u001b[1;35mStep `\u001b[0m\u001b[33;21mimporter`\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mStep `\u001b[0m\u001b[33;21mimporter`\u001b[1;35m has finished in 0.120s.\u001b[0m\n",
      "\u001b[1;35mStep `\u001b[0m\u001b[33;21mdecision_tree_trainer`\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mStep `\u001b[0m\u001b[33;21mdecision_tree_trainer`\u001b[1;35m has finished in 0.065s.\u001b[0m\n",
      "\u001b[1;35mStep `\u001b[0m\u001b[33;21mevaluator`\u001b[1;35m has started.\u001b[0m\n",
      "Test accuracy: 0.7619577308120133\n",
      "\u001b[1;35mStep `\u001b[0m\u001b[33;21mevaluator`\u001b[1;35m has finished in 0.051s.\u001b[0m\n",
      "\u001b[1;35mPipeline run `\u001b[0m\u001b[33;21mstandard_mnist_training_run`\u001b[1;35m has finished in 0.250s.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "RUN_NAME_1 = \"decision_tree_mnist_training_run\"\n",
    "\n",
    "# Initialize the pipeline\n",
    "first_pipeline = mnist_pipeline(\n",
    "    importer=importer(),\n",
    "    trainer=decision_tree_trainer(),\n",
    "    evaluator=evaluator(),\n",
    ")\n",
    "first_pipeline.run(run_name=RUN_NAME_1) # Make sure to change the name if you want to rerun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gotkJdTQz8j2"
   },
   "source": [
    "## Swapping the trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMLU4cNW-Ei4"
   },
   "source": [
    "We got pretty good results on the MNIST model that we trained, but maybe we want to see how a similar training pipeline would work on a different model.\n",
    "\n",
    "You can see how easy it is to switch out one trainer step for another in our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def svc_trainer(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    ") -> ClassifierMixin:\n",
    "    \"\"\"Train another simple sklearn classifier for the digits dataset.\"\"\"\n",
    "    model = SVC(gamma=0.001)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9oQO-ZGE4Kwf",
    "outputId": "c2fb7281-60ee-4126-b859-b8230a1d112b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mCreating run for pipeline: `\u001b[0m\u001b[33;21mmnist_pipeline`\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mCache enabled for pipeline `\u001b[0m\u001b[33;21mmnist_pipeline`\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing stack `\u001b[0m\u001b[33;21mlocal_stack`\u001b[1;35m to run pipeline `\u001b[0m\u001b[33;21mmnist_pipeline`\u001b[1;35m...\u001b[0m\n",
      "\u001b[1;35mStep `\u001b[0m\u001b[33;21mimporter`\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mStep `\u001b[0m\u001b[33;21mimporter`\u001b[1;35m has finished in 0.028s.\u001b[0m\n",
      "\u001b[1;35mStep `\u001b[0m\u001b[33;21msvc_trainer`\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mStep `\u001b[0m\u001b[33;21msvc_trainer`\u001b[1;35m has finished in 0.063s.\u001b[0m\n",
      "\u001b[1;35mStep `\u001b[0m\u001b[33;21mevaluator`\u001b[1;35m has started.\u001b[0m\n",
      "Test accuracy: 0.9688542825361512\n",
      "\u001b[1;35mStep `\u001b[0m\u001b[33;21mevaluator`\u001b[1;35m has finished in 0.058s.\u001b[0m\n",
      "\u001b[1;35mPipeline run `\u001b[0m\u001b[33;21mmnist_training_run_2`\u001b[1;35m has finished in 0.164s.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "RUN_NAME_2 = \"svc_mnist_training_run\"\n",
    "\n",
    "\n",
    "# Initialize a new pipeline\n",
    "second_pipeline = mnist_pipeline(\n",
    "    importer=importer(),\n",
    "    trainer=svc_trainer(),\n",
    "    evaluator=evaluator(),\n",
    ")\n",
    "\n",
    "# Run the new pipeline\n",
    "second_pipeline.run(run_name=RUN_NAME_2) # Make sure to change the name if you want to rerun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post execution workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did mention above that the Materializer takes care of persisting your artifacts for you. But how do you access your runs and their associated artifacts from code? Let's do that step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, we load your repository: this is where all your pipelines live. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.repository import Repository\n",
    "\n",
    "repo = Repository()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how you get all of the pipelines within your repository. Above we reused the same pipeline two times with different importers. We should expect to only see one pipeline named `mnist_pipeline` here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PipelineView(id=1, name='mnist_pipeline')]\n"
     ]
    }
   ],
   "source": [
    "pipelines = repo.get_pipelines()\n",
    "print(pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could now just take the pipeline from above by index using `pipelines[0]`. \n",
    "Alternatively we can get our pipelines by name from our repo. The name of the pipeline defaults to the function name, if not specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_pipeline = repo.get_pipeline(pipeline_name=\"mnist_pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the runs\n",
    "All runs are saved chronologically within the corresponding pipeline. Here you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PipelineRunView(id=2, name='standard_mnist_training_run'), PipelineRunView(id=10, name='mnist_training_run_2')]\n"
     ]
    }
   ],
   "source": [
    "runs = mnist_pipeline.runs  # chronologically ordered\n",
    "print(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first extract out the first run on the standard mnist dataset\n",
    "decision_tree_mnist_run = mnist_pipeline.get_run(RUN_NAME_1)\n",
    "\n",
    "# Now we can extract our second run trained on fashion mnist\n",
    "svc_mnist_run = mnist_pipeline.get_run(RUN_NAME_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StepView(id=1, name='importer', entrypoint_name='importer'parameters={}),\n",
       " StepView(id=2, name='trainer', entrypoint_name='decision_tree_trainer'parameters={}),\n",
       " StepView(id=3, name='evaluator', entrypoint_name='evaluator'parameters={})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_mnist_run.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StepView(id=4, name='importer', entrypoint_name='importer'parameters={}),\n",
       " StepView(id=5, name='trainer', entrypoint_name='svc_trainer'parameters={}),\n",
       " StepView(id=6, name='evaluator', entrypoint_name='evaluator'parameters={})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_mnist_run.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the results of the evaluator and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_eval_step = decision_tree_mnist_run.get_step(name='evaluator')\n",
    "svc_eval_step = svc_mnist_run.get_step(name='evaluator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619577308120133"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One output is simply called `output`, multiple is a dict called `outputs`.\n",
    "decision_tree_eval_step.output.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9688542825361512"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_eval_step.output.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOJtVVaFzlUO"
   },
   "source": [
    "… and that's it for the quickstart. If you came here without a hiccup, you must have successly installed ZenML, set up a ZenML repo, configured a training pipeline, executed it and evaluated the results. And, this is just the tip of the iceberg on the capabilities of ZenML.\n",
    "\n",
    "However, if you had a hiccup or you have some suggestions/questions regarding our framework, you can always check our [docs](https://docs.zenml.io/) or our [Github](https://github.com/zenml-io/zenml) or even better join us on our [Slack channel](https://zenml.io/slack-invite).\n",
    "\n",
    "Cheers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22gkBKSntlF8"
   },
   "source": [
    "For more detailed information on all the components and steps that went into this short example, please continue reading [our more detailed documentation pages](https://docs.zenml.io/)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ZenML Quickstart.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
