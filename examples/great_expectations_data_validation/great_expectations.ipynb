{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO_v5iIaYFi2"
   },
   "source": [
    "# ZenML Data Validation With Great Expectations\n",
    "\n",
    "## Purpose\n",
    "\n",
    "In data-centric machine learning development, data quality is critical not only\n",
    "to achieve good initial results but also to keep data drift and concept drift\n",
    "at bay as your models are deployed to production and interact with live data.\n",
    "\n",
    "Data validation tools can be employed early on in your machine learning\n",
    "pipelines to generate data statistical profiles and infer validation rules\n",
    "that can be used to continuously validate the data being ingested at various\n",
    "points in the pipeline. For example, data validation rules can be inferred from\n",
    "the training dataset and then used to validate the datasets used to perform\n",
    "batch predictions. This is one good way of detecting training-serving skew.\n",
    "\n",
    "This example uses the very popular [`Great Expectations`](https://greatexpectations.io/)\n",
    "open-source library to run data quality tasks on [the University of Wisconsin breast cancer diagnosis\n",
    "dataset](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic))\n",
    "to illustrate how it works.\n",
    "\n",
    "If you want to run this notebook in an interactive environment, feel free to run\n",
    "it in a [Google Colab](https://colab.research.google.com/github/zenml-io/zenml/blob/main/examples/great_expectations_data_validation/great_expectations.ipynb)\n",
    "or view it on [GitHub](https://github.com/zenml-io/zenml/tree/main/examples/great_expectations_data_validation) directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNLEesHEyjkg"
   },
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7l4qDgcI_5F",
    "outputId": "ed764976-0d95-4e5f-e75d-805d2bab804c"
   },
   "outputs": [],
   "source": [
    "# Install the ZenML CLI tool, Great Expectations and scikit-learn\n",
    "import IPython\n",
    "\n",
    "!pip install zenml \n",
    "!zenml integration install -y great_expectations sklearn dash s3\n",
    "\n",
    "# automatically restart kernel\n",
    "IPython.Application.instance().kernel.do_shutdown(restart=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_RCPyaNzPy-"
   },
   "source": [
    "Once the installation is completed, you can go ahead and create a ZenML repository for this project by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lcfE3l2zTU-",
    "outputId": "3d3e70af-c87a-4ac9-917d-b322823431e1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize a ZenML repository\n",
    "!zenml init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNLEesHEyjkg"
   },
   "source": [
    "## Setup the Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we configure a ZenML Stack featuring Great Expectations as a Data Validator and a cloud Artifact Store that uses a managed object storage service (AWS S3) as a backend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZenML and Great Expectations: Store Great Expectations artifacts with the ZenML cloud artifact store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a ZenML stack that includes an Artifact Store connected to a cloud\n",
    "object storage. This example uses AWS as a backend, but [the ZenML documentation](https://docs.zenml.io/component-gallery/artifact-stores/artifact-stores)\n",
    "has similar instructions on how to configure a GCP or Azure Blob Storage powered\n",
    "Artifact Store.\n",
    "\n",
    "For this stack, you will need an S3 bucket where our ML artifacts can later be\n",
    "stored. You can configure one by following [this AWS tutorial](https://docs.aws.amazon.com/AmazonS3/latest/userguide/create-bucket-overview.html).\n",
    "\n",
    "The path for your bucket should be in this format: `s3://your-bucket`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Great Expectations Stack on S3](great_expectations_stack.png \"Great Expectations Stack on S3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!zenml artifact-store register s3_store --flavor=s3 --path=s3://greatexpectationsexample\n",
    "!zenml data-validator register ge_s3 --flavor=great_expectations\n",
    "!zenml stack register s3_stack -o default -a s3_store -dv ge_s3\n",
    "!zenml stack set s3_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQE8PSXDzL-_"
   },
   "source": [
    "Now, the setup is completed. For the next steps, just make sure that you are executing the code within your ZenML repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izjbDO-6yrFM"
   },
   "source": [
    "## Import relevant packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gtj5QKCnSj0"
   },
   "source": [
    "We will use pipelines and steps to validate our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LvFo9epOUE7G",
    "outputId": "42bec4a0-41f9-4560-e9a1-e139f08c4e0a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "from great_expectations.checkpoint.types.checkpoint_result import (  # type: ignore[import]\n",
    "    CheckpointResult,\n",
    ")\n",
    "\n",
    "from zenml.integrations.constants import GREAT_EXPECTATIONS, SKLEARN\n",
    "from zenml.integrations.great_expectations.steps import (\n",
    "    GreatExpectationsProfilerParameters,\n",
    "    GreatExpectationsProfilerStep,\n",
    "    GreatExpectationsValidatorParameters,\n",
    "    GreatExpectationsValidatorStep,\n",
    ")\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.steps import BaseParameters, Output, step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UwqjAR2yvH_"
   },
   "source": [
    "## Define ZenML Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wHcI2FinX2O"
   },
   "source": [
    "In the code that follows, we are defining the various steps of our pipeline. Each step is decorated with `@step`, the main abstraction that is currently available for creating pipeline steps, with the exception of the Great Expectations data profiling and data validation built-in steps that are shipped with ZenML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZI9i2FJ0k3H"
   },
   "source": [
    "The first step is an `importer` step that downloads the breast cancer Wisconsin dataset and returns it as a panda DataFrame. It is used to simulate loading data from two different sources:\n",
    "\n",
    "* reference data used to train a model\n",
    "* \"live\" data that is used in a pipeline to run batch predictions on a model e.g. in production\n",
    "\n",
    "If `reference_data` is set in the step configuration, a slice of the data is returned as a reference dataset. Otherwise, a different slice is returned representing the \"live\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1VT_PAW10jbp",
    "outputId": "36ecdd08-3bca-42b4-d84d-be76126840e8"
   },
   "outputs": [],
   "source": [
    "class DataLoaderParameters(BaseParameters):\n",
    "    reference_data: bool = True\n",
    "    \n",
    "@step\n",
    "def importer(\n",
    "        params: DataLoaderParameters,\n",
    ") -> Output(dataset=pd.DataFrame, condition=bool):\n",
    "    \"\"\"Load the breast cancer dataset.\n",
    "    \n",
    "    This step is used to simulate loading data from two different sources.\n",
    "    If `reference_data` is set in the step configuration, a slice of the\n",
    "    data is returned as a reference dataset. Otherwise, a different slice\n",
    "    is returned as a test dataset to be validated.\n",
    "    \"\"\"\n",
    "    breast_cancer = datasets.load_breast_cancer()\n",
    "    df = pd.DataFrame(\n",
    "        data=breast_cancer.data, columns=breast_cancer.feature_names\n",
    "    )\n",
    "    df[\"class\"] = breast_cancer.target\n",
    "    if params.reference_data:\n",
    "        dataset = df[100:] \n",
    "    else:\n",
    "        dataset = df[:100]\n",
    "    return dataset, params.reference_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aU9ygH9s1BgR"
   },
   "source": [
    "Next, we add the Great Expectations steps that we'll use to perform data\n",
    "profiling and data validation. These steps are already defined as part of the\n",
    "ZenML library, so we only need to add them to our pipeline with a custom\n",
    "configuration.\n",
    "\n",
    "Under the hood, ZenML uses Great Expectations in the implementation of these\n",
    "steps to generate an Expectation Suite from an input dataset and to validate\n",
    "an input dataset using an existing Expectation Suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37mMICD_URDW",
    "outputId": "873fe64b-1105-4181-8541-c31356069305"
   },
   "outputs": [],
   "source": [
    "# instantiate a builtin Great Expectations data profiling step\n",
    "ge_profiler_params = GreatExpectationsProfilerParameters(\n",
    "    expectation_suite_name=\"breast_cancer_suite\",\n",
    "    data_asset_name=\"breast_cancer_ref_df\",\n",
    ")\n",
    "ge_profiler_step = GreatExpectationsProfilerStep(params=ge_profiler_params)\n",
    "\n",
    "\n",
    "# instantiate a builtin Great Expectations data validation step\n",
    "ge_validator_params = GreatExpectationsValidatorParameters(\n",
    "    expectation_suite_name=\"breast_cancer_suite\",\n",
    "    data_asset_name=\"breast_cancer_test_df\",\n",
    ")\n",
    "ge_validator_step = GreatExpectationsValidatorStep(params=ge_validator_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aU9ygH9s1BgR"
   },
   "source": [
    "This next step serves as an example showing how the Great Expectations validation result returned as output from the validator step can be used in other steps in the pipeline to analyze the results in detail and take different actions depending on the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37mMICD_URDW",
    "outputId": "873fe64b-1105-4181-8541-c31356069305"
   },
   "outputs": [],
   "source": [
    "from zenml.steps import (\n",
    "    STEP_ENVIRONMENT_NAME,\n",
    "    StepEnvironment,\n",
    ")\n",
    "from zenml.environment import Environment\n",
    "from typing import cast\n",
    "\n",
    "@step\n",
    "def analyze_result(\n",
    "    result: CheckpointResult,\n",
    ") -> str:\n",
    "    \"\"\"Analyze the Great Expectations validation result and return a true/false value indicating\n",
    "    whether it passed or failed.\"\"\"\n",
    "    step_env = cast(StepEnvironment, Environment()[STEP_ENVIRONMENT_NAME])\n",
    "    pipeline_name = step_env.pipeline_name\n",
    "    run_name = step_env.run_name\n",
    "    step_name = step_env.step_name\n",
    "    pipeline_context = f\"Pipeline {pipeline_name}, with run {run_name}, in step {step_name} produced the following output:\\n\\n\"\n",
    "    if result.success:\n",
    "        message = pipeline_context + \"Great Expectations data validation was successful!\"\n",
    "    else:\n",
    "        message = pipeline_context + \"Great Expectations data validation failed!\"\n",
    "    print(message)\n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_iZTIz8y7Cp"
   },
   "source": [
    "## Define ZenML Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKbU3WlbnoiA"
   },
   "source": [
    "A pipeline is defined with the `@pipeline` decorator. This defines the various steps of the pipeline and specifies the dependencies between the steps, thereby determining the order in which they will be run.\n",
    "\n",
    "We'll define two ZenML pipelines:\n",
    "\n",
    "* a data profiling pipeline. The pipeline imports a reference dataset from a source then uses the builtin Great Expectations profiler step to generate an expectation suite (i.e. validation rules) inferred from the schema and statistical properties of the reference dataset. In more complete use-cases, this would be the model training pipeline and the profiled dataset would be the training dataset.\n",
    "\n",
    "* a data validation pipeline. The pipeline imports \"live\" data from a source, then uses the builtin Great Expectations data validation step to validate the dataset against the expectation suite generated in the profiling pipeline. In more complete use-cases, this would be the batch inference pipeline and the validated dataset would be the \"live\" inference dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rm8SIrLFWenn"
   },
   "outputs": [],
   "source": [
    "from zenml.config import DockerSettings\n",
    "docker_settings = DockerSettings(required_integrations=[SKLEARN, GREAT_EXPECTATIONS])\n",
    "\n",
    "@pipeline(enable_cache=False, settings={\"docker\": docker_settings})\n",
    "def profiling_pipeline(\n",
    "    importer, profiler\n",
    "):\n",
    "    \"\"\"Data profiling pipeline for Great Expectations.\n",
    "\n",
    "    The pipeline imports a reference dataset from a source then uses the builtin\n",
    "    Great Expectations profiler step to generate an expectation suite (i.e.\n",
    "    validation rules) inferred from the schema and statistical properties of the\n",
    "    reference dataset.\n",
    "\n",
    "    Args:\n",
    "        importer: reference data importer step\n",
    "        profiler: data profiler step\n",
    "    \"\"\"\n",
    "    dataset, _ = importer()\n",
    "    profiler(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.config import DockerSettings\n",
    "docker_settings = DockerSettings(required_integrations=[SKLEARN, GREAT_EXPECTATIONS])\n",
    "\n",
    "@pipeline(enable_cache=False, settings={\"docker\": docker_settings})\n",
    "def validation_pipeline(\n",
    "    importer, validator, checker\n",
    "):\n",
    "    \"\"\"Data validation pipeline for Great Expectations.\n",
    "\n",
    "    The pipeline imports a test data from a source, then uses the builtin\n",
    "    Great Expectations data validation step to validate the dataset against\n",
    "    the expectation suite generated in the profiling pipeline.\n",
    "\n",
    "    Args:\n",
    "        importer: test data importer step\n",
    "        validator: dataset validation step\n",
    "        checker: checks the validation results\n",
    "    \"\"\"\n",
    "    dataset, condition = importer()\n",
    "    results = validator(dataset, condition)\n",
    "    message = checker(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-JtDHu_z1IX"
   },
   "source": [
    "## Run the pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrJA5OSgnydC"
   },
   "source": [
    "Running the pipelines is as simple as calling the `run()` method on an instance of the defined pipeline. You can also switch between the ZenML stacks we configured at the beginning of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRzZA406UVVz",
    "outputId": "2d5e9967-87b7-4553-a104-b1b6602e10a6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profiling_pipeline(\n",
    "    importer=importer(params=DataLoaderParameters(reference_data=True)),\n",
    "    profiler=ge_profiler_step,\n",
    ").run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_pipeline(\n",
    "    importer=importer(params=DataLoaderParameters(reference_data=False)),\n",
    "    validator=ge_validator_step,\n",
    "    checker=analyze_result(),\n",
    ").run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-execution workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we setup some helper functions that we'll use to visualize the pipelines and the artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.post_execution import get_pipeline\n",
    "\n",
    "def visualize_results(pipeline_name: str, step_name: str) -> None:\n",
    "    pipeline = get_pipeline(pipeline_name)\n",
    "    last_run = pipeline.runs[0]\n",
    "    step = last_run.get_step(step=step_name)\n",
    "    step.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both ZenML and Great Expectations takes care of persisting the Expectation Suites and data validation results in the Artifact Store. These artifacts can be extracted and visualized after the pipeline runs are complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_results(\"profiling_pipeline\", \"profiler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_results(\"validation_pipeline\", \"validator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOJtVVaFzlUO"
   },
   "source": [
    "You have successfully used ZenML and Great Expectations to validate data and visualize data validation reports.\n",
    "\n",
    "For more ZenML features and use-cases, you should check out some of the other ZenML examples. You should also take a look at our [docs](https://docs.zenml.io/) or our [Github](https://github.com/zenml-io/zenml) repo, or even better, join us on our [Slack channel](https://zenml.io/slack-invite).\n",
    "\n",
    "Cheers!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ZenML Quickstart.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "59ea241ca7da22c5404bcbb852ad4320b36fe5cff8b75f653e561d6b88a3302f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
