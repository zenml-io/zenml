#!/usr/bin/env bash
# Generate Quickstart Cloud Requirements
#
# Regenerates examples/quickstart/requirements_{aws,azure,gcp}.txt from:
# - a base requirements file, and
# - ZenML integration metadata (via `zenml integration export-requirements`).
#
# Why this exists:
# - Keeps provider-specific requirements aligned with ZenML integration definitions.
# - Ensures the pinned ZenML version is consistent across release preparations.
# - Produces deterministic, deduplicated outputs written atomically for CI stability.

set -euo pipefail

usage() {
  cat <<'USAGE'
Usage:
  scripts/generate_cloud_requirements.sh
    [--base <path>]             # Default: examples/quickstart/requirements.txt
    [--out-dir <path>]          # Default: examples/quickstart
    --zenml-version <X.Y.Z>     # Required
    [--clouds <csv>]            # Default: aws,azure,gcp
    [-h|--help]

Description:
  Generates provider-specific requirements files for the Quickstart example:
    - requirements_aws.txt
    - requirements_azure.txt
    - requirements_gcp.txt

  Each file contains:
    1) A header noting the file is auto-generated.
    2) Pinned zenml[server]==<ZENML_VERSION> as the first requirement.
    3) Base requirements (excluding any line that mentions 'zenml[server]'), preserving order.
    4) A section with the exported integration requirements for the provider.
    5) Global de-duplication while preserving the first occurrence order.

Notes:
  - Output files are written atomically via a temp file + mv.
  - The script fails if the integration export is empty or if the base file is missing.

Examples:
  scripts/generate_cloud_requirements.sh --zenml-version 0.90.0
  scripts/generate_cloud_requirements.sh --base path/to/base.txt --out-dir examples/quickstart --zenml-version 0.90.0 --clouds aws,gcp
USAGE
}

# Defaults
BASE="examples/quickstart/requirements.txt"
OUT_DIR="examples/quickstart"
ZENML_VERSION=""
CLOUDS="aws,azure,gcp"

# Parse arguments
while [[ $# -gt 0 ]]; do
  case "$1" in
    --base)
      BASE="${2:-}"; shift 2;;
    --out-dir)
      OUT_DIR="${2:-}"; shift 2;;
    --zenml-version)
      ZENML_VERSION="${2:-}"; shift 2;;
    --clouds)
      CLOUDS="${2:-}"; shift 2;;
    -h|--help)
      usage; exit 0;;
    *)
      echo "Error: Unknown argument: $1" >&2
      usage
      exit 1;;
  esac
done

# Validate required arguments and inputs
if [[ -z "${ZENML_VERSION}" ]]; then
  echo "Error: --zenml-version is required (e.g., --zenml-version 0.90.0)." >&2
  usage
  exit 1
fi

if [[ ! -f "${BASE}" ]]; then
  echo "Error: Base requirements file not found: ${BASE}" >&2
  exit 1
fi

mkdir -p "${OUT_DIR}"

# Normalize clouds CSV to an array
IFS=',' read -r -a CLOUD_ARRAY <<< "${CLOUDS}"

# Helper to export integration requirements as one requirement per line.
# Some exports can be whitespace-separated; we normalize to newline-separated tokens.
_export_integration_requirements() {
  local cloud="$1"
  local raw_output
  if ! raw_output="$(zenml integration export-requirements "${cloud}" 2>&1)"; then
    echo "Error: Failed to export requirements for integration '${cloud}'." >&2
    echo "Output:" >&2
    echo "${raw_output}" >&2
    return 1
  fi

  # Convert any whitespace (spaces/tabs/newlines) into single newlines, strip blanks.
  # This ensures we get one requirement per line regardless of the export format.
  # Note: Pip requirement spec rarely contains spaces; if present, this would split them.
  #       If that ever becomes an issue, adjust this normalization accordingly.
  printf "%s" "${raw_output}" | tr -s '[:space:]' '\n' | sed -E '/^[[:space:]]*$/d'
}

for cloud in "${CLOUD_ARRAY[@]}"; do
  cloud_trimmed="$(printf "%s" "${cloud}" | sed -E 's/^[[:space:]]+|[[:space:]]+$//g')"
  if [[ -z "${cloud_trimmed}" ]]; then
    continue
  fi

  out_file="${OUT_DIR}/requirements_${cloud_trimmed}.txt"
  tmp_file="$(mktemp "${OUT_DIR}/requirements_${cloud_trimmed}.tmp.XXXXXX")"
  tmp_dedup="$(mktemp "${OUT_DIR}/requirements_${cloud_trimmed}.dedup.XXXXXX")"

  echo "=== Generating ${out_file} ==="
  echo "-> Exporting integration requirements for '${cloud_trimmed}'..."
  export_lines="$(_export_integration_requirements "${cloud_trimmed}")" || {
    echo "Error: Could not retrieve requirements for '${cloud_trimmed}'. Aborting." >&2
    rm -f "${tmp_file}" "${tmp_dedup}" || true
    exit 1
  }

  if [[ -z "${export_lines}" ]]; then
    echo "Error: Integration '${cloud_trimmed}' returned no requirements. Failing to avoid empty output." >&2
    rm -f "${tmp_file}" "${tmp_dedup}" || true
    exit 1
  fi

  {
    echo "# Auto-generated by scripts/generate_cloud_requirements.sh - DO NOT EDIT"
    echo "# Cloud integration: ${cloud_trimmed}"
    echo "zenml[server]==${ZENML_VERSION}"
    # Append base requirements while excluding any line that mentions 'zenml[server]' anywhere
    # to avoid duplicate pins or git-egg variants. Order for the remaining lines is preserved.
    grep -E -v 'zenml\[server\]' "${BASE}" || true
    echo ""
    echo "# ${cloud_trimmed} integration requirements"
    # Write the exported requirements, one per line
    printf "%s\n" "${export_lines}"
  } > "${tmp_file}"

  # Deduplicate globally while preserving the first occurrence order.
  # This avoids duplicates that may arise when base reqs already include some integration deps.
  awk '!seen[$0]++' "${tmp_file}" > "${tmp_dedup}"

  # Atomic move into place
  mv -f "${tmp_dedup}" "${out_file}"
  rm -f "${tmp_file}" || true

  echo "-> Wrote ${out_file}"
done

echo "=== Done generating cloud requirements for: ${CLOUDS} ==="